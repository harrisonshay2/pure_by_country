---
title: 'By Country: Pure Clusters'
output: html_document
---
```{r include=F}
knitr::opts_chunk$set(echo=F)
knitr::opts_chunk$set(warning=F)
knitr::opts_chunk$set(message=F)

setwd("~/centauri/")
library(tidyverse)
library(readr)
library(kableExtra)
library(knitr)
library(lubridate)
library(DT)
library(RColorBrewer)
library(stringr)
library(scales)
Sys.setenv(TZ='EST')
mcma_objs = readRDS("~/centauri/conjunction_analysis/RDSfiles/mcma_objs")
all_conjs_pure = readRDS("~/centauri/all_conjs_pure")
derelicts = readRDS("~/centauri/conjunction_analysis/RDSfiles/derelicts")
derelictDat = readRDS("~/centauri/conjunction_analysis/RDSfiles/derelictDatNew")
alt_bins = readRDS("~/centauri/conjunction_analysis/RDSfiles/alt_bins")
file_list_pure = readRDS("~/centauri/conjunction_analysis/RDSfiles/file_list_pure")
today = toupper(strftime(Sys.Date(), format="%d%b%Y")) # current day
path = "~conjunction_analysis/conj_data/"
#all_conjs_expanded_pure = readRDS("~/pure_by_country/all_conjs_expanded_pure")
```

```{r update_conj_files, warning=F}
# # add new conjunction files to all_conjs dataframe
# 
# # read in new conjunction files
# file_list_new_pure = list.files("C:/Users/Harri/OneDrive/Documents/centauri/conjunction_analysis/conj_data")
# file_list_new_pure = file_list_new_pure[!(file_list_new_pure %in% file_list_pure)] # only the new conjunctions
# 
# colnames = c("PrimarySatellite","SecondarySatellite","TCA_EpDay",
#              "TCA_UTCG","Range","RangeX","RangeY","RangeZ","Velocity",
#              "VelocityX","VelocityY","VelocityZ","Latitude","Longitude",
#              "Altitude","PrimaryAge","SecondaryAge","PrimaryCluster",
#              "SecondaryCluster","DateGenerated","del")
# 
# all_conjs_pure_new = data.frame()
# for (i in 1:length(file_list_new_pure)) {
#   file = paste0("C:/Users/Harri/OneDrive/Documents/centauri/conjunction_analysis/conj_data/", file_list_new_pure[i])
#   
#   firstLine = readLines(file, n=2)[2]
#   
#   if (str_count(firstLine, ',') == 20) { # if file has trailing commas
#     temp_data = read_csv(file, skip=1, col_names = colnames, 
#                          col_types = "ccncnnnnnnnnnnncccccc") %>%
#       select(-del)
#   } else {
#     temp_data = read_csv(file, skip=1, 
#                          col_names = colnames[-length(colnames)], 
#                          col_types = "ccncnnnnnnnnnnnccccc")
#   }
#   
#   all_conjs_pure_new = rbind(all_conjs_pure_new, temp_data) #for each iteration, bind the new data to the building dataset
# }
# 
# mycols <- '(PrimaryCluster, SecondaryCluster)'
# minf <- paste0('min',mycols)
# maxf <- paste0('max',mycols)
# 
# all_conjs_pure_new = all_conjs_pure_new %>%
#   mutate(DateGenerated = parse_date_time(DateGenerated, tz="EST", 
#                                    orders=c("%Y-%m-%d %H:%M:%S", "%m/%d/%y %H:%M")),
#          date = DateGenerated - 24*60*60,
#          utcg = if_else(nchar(TCA_UTCG) > 7,
#                         as.POSIXct(TCA_UTCG, format="%Y-%m-%d %H:%M:%S"),
#                         date + TCA_EpDay*24*60*60),
#          TCA_UTCG = utcg) %>% 
#  select(-c(date, utcg)) %>%
#  rowwise() %>% 
#  mutate(firstClust = eval(parse(text=minf)),
#          secondClust = eval(parse(text=maxf)),
#          clusters = paste(firstClust, secondClust, sep="-")) #%>% 
#  # ungroup() %>%
#   #mutate(clusterLab = if_else(firstClust=="LEO" & secondClust=="LEO", "LEO",
#    #                           if_else((firstClust=="LEO" & secondClust!="LEO") |
#     #                                    (firstClust!="LEO" & secondClust=="LEO"), "LEO-other",
#                                       #if_else(firstClust=="HIGH" & secondClust=="HIGH", "HIGH",
#                                               #if_else((firstClust=="HIGH" & secondClust!="HIGH") | 
#                                                         #(firstClust!="HIGH" & secondClust=="HIGH"), "HIGH-other",
#                                                       #firstClust)))),
#  #        clusterLab = factor(clusterLab,
#   #                           levels = c("615", "775", "850", "975", "1200", "1500", "LEO","LEO-other","HIGH","HIGH-other"),
#    #                          ordered = T))
# 
# # update file list
# file_list_pure = append(file_list_pure, file_list_new_pure)
# saveRDS(file_list_pure, "RDSfiles/file_list_pure")
# 
# # adding new clustelab
# all_conjs_pure_new = all_conjs_pure_new %>%
#   mutate(noradId_1 = as.numeric(gsub("--.*", "", PrimarySatellite)),
#          noradId_2 = as.numeric(gsub("--.*", "", SecondarySatellite))) %>%
#   left_join(dplyr::select(derelictDat, c(noradId, cluster)), by=c("noradId_1" = "noradId")) %>%
#   rename_at(vars(c(cluster)), function(x) paste0(x, "_1")) %>%
#   left_join(dplyr::select(derelictDat, c(noradId, cluster)), by=c("noradId_2" = "noradId")) %>%
#   rename_at(vars(c(cluster)), function(x) paste0(x, "_2")) %>%
#   dplyr::select(-c(noradId_1, noradId_2))
# 
# #getting rid of 'N' in cluster_1 
# all_conjs_pure_new$cluster_1 <- ifelse(all_conjs_pure_new$cluster_1 %in% c('c775N'), "c775", all_conjs_pure_new$cluster_1)
# all_conjs_pure_new$cluster_1 <- ifelse(all_conjs_pure_new$cluster_1 %in% c('c850N'), "c850", all_conjs_pure_new$cluster_1)
# all_conjs_pure_new$cluster_1 <- ifelse(all_conjs_pure_new$cluster_1 %in% c('c975N'), "c975", all_conjs_pure_new$cluster_1)
# all_conjs_pure_new$cluster_1 <- ifelse(all_conjs_pure_new$cluster_1 %in% c('c1500N'), "c1500", all_conjs_pure_new$cluster_1)
# 
# #getting rid of 'N' in cluster_2 
# all_conjs_pure_new$cluster_2 <- ifelse(all_conjs_pure_new$cluster_2 %in% c('c775N'), "c775", all_conjs_pure_new$cluster_2)
# all_conjs_pure_new$cluster_2 <- ifelse(all_conjs_pure_new$cluster_2 %in% c('c850N'), "c850", all_conjs_pure_new$cluster_2)
# all_conjs_pure_new$cluster_2 <- ifelse(all_conjs_pure_new$cluster_2 %in% c('c975N'), "c975", all_conjs_pure_new$cluster_2)
# all_conjs_pure_new$cluster_2 <- ifelse(all_conjs_pure_new$cluster_2 %in% c('c1500N'), "c1500", all_conjs_pure_new$cluster_2)
# 
# # pure clusterlab
# all_conjs_pure_new = all_conjs_pure_new%>%
# mutate(clusterLab_pure = if_else(cluster_1 == "elsewhere" & cluster_2 == "elsewhere", "no collision", if_else(cluster_1 == "elsewhere" | cluster_2 == "elsewhere", "no collision", if_else(cluster_1 == "cleo" | cluster_2 == "cleo", "LEO-other", if_else(cluster_1 == "cleo" & cluster_2 == "cleo", "LEO",as.character(cluster_1))))),
#                       clusterLab_pure = factor(clusterLab_pure,
#                            levels = c("c775", "c850", "c975", "c1500", "LEO-other","LEO", "no collision"),
#                           ordered = T))
# #all_conjs_pure = rbind(all_conjs_pure,all_conjs_pure_new)
# #saveRDS(all_conjs_pure,"~/centauri/all_conjs_pure")
# 
# 
# #########
# # WORST OFFENDER alg for new conjunctions
# # persistence
#  alts = c(615,775,850,975, 1200,1500)
#  pers = c(25, 90, 150,1000,1600,1800)
#  lw1 <- loess(pers ~ alts)
# 
# # get operational satellites
#  opSats = derelictDat %>% filter(avgAlt < 2000 & operational)
#  
#  combinedMass_v = vector()
#  persistence_v = vector()
#  numOpSats_v = vector()
#  for (i in 1:nrow(all_conjs_pure_new)) {
#    conj = all_conjs[i, ]
#    noradId1 = gsub("--.*", "", conj$PrimarySatellite)
#    noradId2 = gsub("--.*", "", conj$SecondarySatellite)
#    obj1 = filter(derelictDat, noradId == noradId1)
#    obj2 = filter(derelictDat, noradId == noradId2)
#    
#    combinedMass = as.numeric(obj1$mass) + as.numeric(obj2$mass)
#    persistence = if_else(conj$Altitude <= 615, 25,
#                          if_else(conj$Altitude > 615 & conj$Altitude <= 1500, 
#                                  predict(lw1, conj$Altitude), 1000)) 
#    
#     combinedMass_v = append(combinedMass_v, toString(combinedMass))
#    persistence_v = append(persistence_v, persistence)
#   }
#  all_conjs_pure_new$combinedMass = combinedMass_v
#  all_conjs_pure_new$persistence = persistence_v
# 
# # replace missing mass values
#  all_conjs_pure_new = all_conjs_pure_new %>%
#   mutate(combinedMass = if_else(grepl(",", combinedMass, fixed = T), # if it contains a comma
#                                   as.numeric(gsub(",.*", "", combinedMass)), # make substring up to the comma
#                                   as.numeric(combinedMass) )) # otherwise don't change
# 
# # get SD op sats per conj
#  alt_bins = readRDS("~/centauri/conjunction_analysis/RDSfiles/alt_bins")
#  roundDown <- function(x) 10*floor(x/10)
#  library(zoo)
#  alt_bins = derelictDat %>% 
#    filter(avgAlt < 2000 & operational) %>%
#    mutate(altitude = roundDown((as.numeric(apogee) + as.numeric(perigee))/2)) %>% 
#    group_by(altitude) %>% 
#    summarise(numOpSats = n()) %>% 
#    right_join(alt_bins, by="altitude") %>%
#    mutate(numOpSats = replace_na(numOpSats, 0)) %>% 
#    mutate(spatDensOpSats_1 = numOpSats / volume * (10^10)) %>%
#    mutate(SD = rollmean(spatDensOpSats_1, k=5, na.pad=T)) %>% na.omit()
#  
#  all_conjs_pure_new = all_conjs_pure_new %>% 
#    mutate(altitude = roundDown(Altitude)) %>% 
#    left_join(select(alt_bins, c(altitude, SD)), by="altitude") 
#  
#  all_conjs_pure_new = all_conjs_pure_new %>%
#    mutate(risk = (combinedMass + persistence + SD) / Range,
#           conseq = combinedMass + persistence + SD,
#          # initialize scaled variables
#           combinedMass_s = 1, persistence_s = 1,
#           SD_s = 1, Range_s = 1, risk_s = 1, conseq_s=1)
# 
# # append new conjunctions to previous
# #all_conjs = rbind(all_conjs, all_conjs)
# # saveRDS(all_conjs, "RDSfiles/all_conjs") # save to RDS file
# 
# # adjust scaling 
#  all_conjs_pure_new = all_conjs_pure_new %>%
#     mutate(combinedMass_s = scale(combinedMass),#rescale(combinedMass, to=c(0,1000)),
#            persistence_s = scale(persistence), #rescale(persistence, to=c(0,1000)),
#            SD_s = scale(SD), #rescale(SD, to=c(0,1000)),
#           Range_s = if_else(Range >= 1, 10^(Range), 10), #rescale(Range, to=c(1e-4, 100)),
#            conseq = combinedMass + persistence + SD,
#            conseq_s = combinedMass_s + persistence_s + SD_s,
#            risk_s = (combinedMass_s + persistence_s + SD_s) / (Range_s),
#            risk = (combinedMass + persistence + SD) / Range_s) 
#   
#   min_cm = min(all_conjs_pure_new$combinedMass_s, na.rm=T)
#   min_pers = min(all_conjs_pure_new$persistence_s)
#   min_SD = min(all_conjs_pure_new$SD_s)
#   
#  all_conjs_pure_new = all_conjs_pure_new %>%
#     mutate(combinedMass_s = combinedMass_s + abs(min_cm),
#            persistence_s = persistence_s + abs(min_pers),
#            SD_s = SD_s + abs(min_SD),
#            risk_s = (combinedMass_s + persistence_s + SD_s) / (Range_s))
#  
#  all_conjs_pure = rbind(all_conjs_pure,all_conjs_pure_new)
# #saveRDS(all_conjs_pure,"~/centauri/all_conjs_pure")
#  
# pure_cluster_df = all_conjs_pure %>% 
#   mutate(Range = Range) %>%
#   group_by(clusterLab_pure) %>%
#   arrange(Range) %>%
#   mutate(rowid = 1, cumnum = cumsum(rowid))
# # pure_cluster_df_775 = pure_cluster_df[pure_cluster_df$clusterLab_pure %in% "c775",]
# # ln_775 = lm(log(pure_cluster_df_775$Range) ~ log(pure_cluster_df_775$cumnum))
# # 
# # pure_cluster_df_850 = pure_cluster_df[pure_cluster_df$clusterLab_pure %in% "c850",]
# # ln_850 = lm(log(pure_cluster_df_850$Range) ~ log(pure_cluster_df_850$cumnum))
# # 
# # pure_cluster_df_975 = pure_cluster_df[pure_cluster_df$clusterLab_pure %in% "c975",]
# # ln_975 = lm(log(pure_cluster_df_975$Range) ~ log(pure_cluster_df_975$cumnum))
# # 
# # pure_cluster_df_1500 = pure_cluster_df[pure_cluster_df$clusterLab_pure %in% "c1500",]
# # ln_1500 = lm(log(pure_cluster_df_1500$Range) ~ log(pure_cluster_df_1500$cumnum))
# 
# 
# # pure_cluster_df = all_conjs_pure %>% 
# #   mutate(Range = Range * 1000) %>%
# #   group_by(clusterLab_pure) %>%
# #   arrange(Range) %>%
# #   mutate(rowid = 1, cumnum = cumsum(rowid))
# firstSet = all_conjs_pure %>%
#   mutate(noradId = as.numeric(gsub("--.*", "", PrimarySatellite))) %>%
#   dplyr::select(-c(PrimarySatellite, SecondarySatellite))
# 
# secondSet = all_conjs_pure %>%
#   mutate(noradId = as.numeric(gsub("--.*", "", SecondarySatellite))) %>%
#   dplyr::select(-c(PrimarySatellite, SecondarySatellite))
# 
# # append new conjunctions to previous
# all_conjs_expanded_pure = rbind(firstSet, secondSet)
# saveRDS(all_conjs_expanded_pure, "RDSfiles/all_conjs_expanded_pure") # save to RDS file
```

```{r perc_encounters_country, fig.width=7.5}
all_conjs_expanded_pure = readRDS("~/pure_by_country/all_conjs_expanded_pure")
# read in country codes
country_codes = read_csv("./country_codes.csv", 
                         col_names = c("country", "Country"), col_types = "cc", skip = 1) %>%
  mutate(Country = str_to_title(Country),
         Country = if_else(str_length(Country) > 20, country, Country))

# plot percent of encounters by country
p = all_conjs_expanded_pure %>%
  left_join(dplyr::select(derelictDat, c(noradId, country)), by="noradId") %>%
  mutate(country = if_else(country == "CHBZ", "PRC", country),
         country = replace_na(country, "Other")) %>% 
  group_by(clusterLab_pure, country) %>% 
  summarise(numEncounters = n()) %>% 
  left_join(country_codes, by="country") %>% 
  group_by(clusterLab_pure) %>%
  mutate(encountersPerClust = sum(numEncounters), 
         p = numEncounters / encountersPerClust * 100) %>%
  group_by(clusterLab_pure) %>%
  mutate(country_new = if_else(Country %in% c("CIS", "US", "China", "ESA", "France", "Germany", "India", "Japan"), Country, "Other")) %>% 
  group_by(clusterLab_pure, country_new) %>%
  summarise(p = sum(p),
            encountersPerClust = round(min(encountersPerClust)/2)) %>%
  mutate(country_new = factor(country_new, 
                              levels = c("CIS", "US", "China", "ESA", "France", 
                                         "Germany", "India", "Japan", "Other"), 
                              ordered=T))

ggplot() + 
  geom_bar(data = p, aes(x=clusterLab_pure, y=p/100, group=country_new, fill=country_new), stat="identity")+
  geom_text(data = unique(dplyr::select(p, c(clusterLab_pure, encountersPerClust))), position = position_stack(vjust=1.05), 
            aes(x=clusterLab_pure, y=1, label=encountersPerClust))+
  theme_minimal() +
  scale_y_continuous(labels = scales::percent) + 
  scale_fill_brewer(palette = "Set1")+
  labs(x="Cluster",y="", title = "Percent of Encounters by Country - misses within 5 km", fill="Country",
       subtitle="Number of encounters shown above each bar", caption=paste0("Encounters from 31MAR2016-", today))
```

```{r barchart500m, fig.width=7.5}

p = all_conjs_expanded_pure %>%
    filter(Range <= .5) %>%
  left_join(dplyr::select(derelictDat, c(noradId, country)), by="noradId") %>%
  mutate(country = if_else(country == "CHBZ", "PRC", country),
         country = replace_na(country, "Other")) %>% 
  group_by(clusterLab_pure, country) %>% 
  summarise(numEncounters = n()) %>% 
  left_join(country_codes, by="country") %>% 
  group_by(clusterLab_pure) %>%
  mutate(encountersPerClust = sum(numEncounters), 
         p = numEncounters / encountersPerClust * 100) %>%
  group_by(clusterLab_pure) %>%
  mutate(country_new = if_else(Country %in% c("CIS", "US", "China", "ESA", "France", "Germany", "India", "Japan"), Country, "Other")) %>% 
  group_by(clusterLab_pure, country_new) %>%
  summarise(p = sum(p),
            encountersPerClust = round(min(encountersPerClust)/2)) %>%
  mutate(country_new = factor(country_new, 
                              levels = c("CIS", "US", "China", "ESA", "France", 
                                         "Germany", "India", "Japan", "Other"), 
                              ordered=T))

ggplot() + 
  geom_bar(data = p, aes(x=clusterLab_pure, y=p/100, group=country_new, fill=country_new), stat="identity")+
  geom_text(data = unique(dplyr::select(p, c(clusterLab_pure, encountersPerClust))), position = position_stack(vjust=1.05), 
            aes(x=clusterLab_pure, y=1, label=encountersPerClust))+
  theme_minimal() +
  scale_y_continuous(labels = scales::percent) + 
  scale_fill_brewer(palette = "Set1")+
  labs(x="Cluster",y="", title = "Percent of Encounters by Country - misses within 500 m", fill="Country",
       subtitle="Number of encounters shown above each bar", caption=paste0("Encounters from 31OCT2016-", today))
```
